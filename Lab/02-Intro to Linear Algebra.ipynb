{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb2fb67",
   "metadata": {},
   "source": [
    "## Segment 1: Data Structures for Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e020dc",
   "metadata": {},
   "source": [
    "### Scalars (Rank 0 Tensors) in Base Python\n",
    "* No Dimensions\n",
    "* Single Number\n",
    "* Denoted in <font color=blue>_lowercase, italics_</font> , e.g.: <font color=green>_x_</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a8a0a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 7\n",
      "   type(x) = <class 'int'>\n",
      "y = 3.5\n",
      "   type(y) = <class 'float'>\n",
      "sum = 10.5\n",
      "   type(sum) = <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "x = 7\n",
    "y = 3.5\n",
    "py_sum = x + y\n",
    "\n",
    "print(f\"x = {x}\\n   type(x) = {type(x)}\\ny = {y}\\n   type(y) = {type(y)}\\nsum = {py_sum}\\n   type(sum) = {type(py_sum)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d639c4",
   "metadata": {},
   "source": [
    "### Scalars in PyTorch\n",
    "\n",
    "* PyTorch and TensorFlow are the two most popular *automatic differentiation* libraries  in Python, itself the most popular programming language in ML\n",
    "* PyTorch tensors are designed to be pythonic, i.e., to feel and behave like NumPy arrays\n",
    "* The advantage of PyTorch tensors relative to NumPy arrays is that they easily be used for operations on GPU (see [here](https://pytorch.org/tutorials/beginner/examples_tensor/two_layer_net_tensor.html) for example) \n",
    "* Documentation on PyTorch tensors, including available data types, is [here](https://pytorch.org/docs/stable/tensors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d960d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e241ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.tensor(7)\n",
    "x_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5358095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a87ce",
   "metadata": {},
   "source": [
    "### Vectors (Rank 1 Tensors) in NumPy\n",
    "* One-dimensional array\n",
    "* Arranged in an order, so element can be accessed by its index\n",
    "   * Elements are scalars so not bold\n",
    "* Representing a point in space\n",
    "   * Vector of length two represents location in 2D matrix\n",
    "   * Length of three represents location in 3d cube\n",
    "   * Length of n represents location in n-dimensional tensor\n",
    "* Denoted in <font color=blue>_lowercase, italics, Bold_</font> , e.g.: <font color=green><b>_x_<b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d39a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73841ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13, 42])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([7, 13, 42])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6667f188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260af96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a11826f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d799a638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b531c487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba5050e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13, 42])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transposing a regular 1-D array has no effect...\n",
    "x_t = x.T\n",
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "448ba96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb65d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 13, 42]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...but it does we use nested \"matrix-style\" brackets: \n",
    "y = np.array([[7, 13, 42]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53bf49f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d8f40d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7],\n",
       "       [13],\n",
       "       [42]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t = y.T\n",
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a119d4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b988f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 13, 42]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe05095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc6d30",
   "metadata": {},
   "source": [
    "### Zero Vectors\n",
    "\n",
    "Have no effect if added to another vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cddec88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros(3)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3267be",
   "metadata": {},
   "source": [
    "### Vectors in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c3ab740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 13, 42])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.tensor([7, 13, 42])\n",
    "x_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a560da",
   "metadata": {},
   "source": [
    "### Norm\n",
    "* Norms are function that quantify vector magnitude\n",
    "\n",
    "### $L^2$ Norm\n",
    "* Discribed by: <font color=red>$||x||_{2}=\\sqrt{\\sum_{i} x_i^2}$</font>\n",
    "\n",
    "* Measures simple (Euclidean) distance from origin\n",
    "\n",
    "* Most common norm in machine learning\n",
    "\n",
    "* Instead of <font color=blue>$||x||_{2}$</font>, it can be denote as <font color=blue>$||x||$</font>\n",
    "\n",
    "* If ||__x__|| = 1, __x__ is  <font color=blue>_\"Unit vector\"_</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "065152f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13, 42])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f01d4af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.51965857910413"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7**2 + 13**2 + 42**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba9f7ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.51965857910413"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201587d7",
   "metadata": {},
   "source": [
    "### $L^1$ Norm\n",
    "\n",
    "* Discribed by: <font color=red>$||x||_{1}=\\sum_{i} |x_i|$</font>\n",
    "* Another common norm in ML\n",
    "* used whenever difference between zero and non-zero is key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "622031dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13, 42])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cda1617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(7) + np.abs(13) + np.abs(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37975759",
   "metadata": {},
   "source": [
    "### Generalized $L^p$ Norm\n",
    "\n",
    "* Discribed by: <font color=red>$||x||_{p}=(\\sum_{i} |x_i|^p)^{1/p}$</font>\n",
    "* p must be :\n",
    "   * A real number\n",
    "   * Greater than or equal to one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5215c84",
   "metadata": {},
   "source": [
    "### Squared $L^2$ Norm\n",
    "\n",
    "Discribed by: <font color=red>$||x||_{2}^2=\\sum_{i} x_i^2 = x^Tx$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce9b96b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13, 42])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc4e5fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1982"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7**2 + 13**2 + 42**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "100a8ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1982"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll cover tensor multiplication more soon but to prove point quickly: \n",
    "np.dot(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8f9ef",
   "metadata": {},
   "source": [
    "### Max Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7d51bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13, 42])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63597091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([np.abs(7), np.abs(13), np.abs(42)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13221aa",
   "metadata": {},
   "source": [
    "### Orthogonal Vectors\n",
    "\n",
    "* x and y are orthogonal vectors if <font color=red>$x^Ty = 0$</font>\n",
    "* n-dimensional space has max n mutually orthogonal vectors\n",
    "* <font color=blue>_\"Orthonormal vectors\"_</font> are orthogonal and all have unit norm\n",
    "   * Basis vectors are an example, i=(1,0), j=(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65dd24f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.array([1, 0])\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bf0ddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = np.array([0, 1])\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40b50f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(i, j) # detail on the dot operation coming up..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed9a18",
   "metadata": {},
   "source": [
    "### Matrices (Rank 2 Tensors) in NumPy\n",
    "\n",
    "* Two-dimensional array of numbers\n",
    "* Denoted in <font color=blue>_Uppercase, Italics, Bold_</font> , e.g.: <font color=green><b>_X_<b></font>\n",
    "* Individual scalar elements denoted in uppercase, italics only\n",
    "    * Element in top-left corner of matrix <font color=green><b>_X_<b></font> above would be <font color=green>$X_{0, 0}$</font>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f62a0260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use array() with nested brackets: \n",
    "X = np.array([[25, 2], [5, 26], [3, 7]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4573e38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e44869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "beacae93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25,  5,  3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select left column of matrix X (zero-indexed)\n",
    "X[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86dbef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 26])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select middle row of matrix X: \n",
    "X[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a82cbd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another slicing-by-index example: \n",
    "X[0:2, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c8d9f",
   "metadata": {},
   "source": [
    "### Matrices in PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72d44525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25,  2],\n",
       "        [ 5, 26],\n",
       "        [ 3,  7]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pt = torch.tensor([[25, 2], [5, 26], [3, 7]])\n",
    "X_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b93b671d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f048fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 26])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pt[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ecd096",
   "metadata": {},
   "source": [
    "### Higher-Rank Tensors\n",
    "\n",
    "* Denoted in <font color=blue>_Uppercase, Italics, Bold, Sans Serif_</font> \n",
    "\n",
    "As an example, rank 4 tensors are common for images, where each dimension corresponds to: \n",
    "\n",
    "1. Number of images in training batch, e.g., 32\n",
    "2. Image height in pixels, e.g., 28\n",
    "3. Image width in pixels, e.g., 28\n",
    "4. Number of color channels, e.g., 3 for full-color images (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "339c4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_pt = torch.zeros([32, 28, 28, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "832ee8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbffcba",
   "metadata": {},
   "source": [
    "# Segment 2: Common Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33884e2b",
   "metadata": {},
   "source": [
    "### Tensor Transposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84cb73a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a86ce6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1c42a1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  5,  3],\n",
       "       [ 2, 26,  7]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc42f2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25,  5,  3],\n",
       "        [ 2, 26,  7]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pt.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96539243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3db175",
   "metadata": {},
   "source": [
    "### Basic Arithmetical Properties\n",
    "Adding or multiplying with scalar applies operation to all elements and tensor shape is retained: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56542797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c7cd6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  4],\n",
       "       [10, 52],\n",
       "       [ 6, 14]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82f9efb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  4],\n",
       "       [ 7, 28],\n",
       "       [ 5,  9]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44a03863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52,  6],\n",
       "       [12, 54],\n",
       "       [ 8, 16]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X*2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ee979a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[52,  6],\n",
       "        [12, 54],\n",
       "        [ 8, 16]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pt*2+2 # could alternatively use torch.mul() or torch.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2981c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[52,  6],\n",
       "        [12, 54],\n",
       "        [ 8, 16]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(torch.mul(X_pt, 2), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d975a98",
   "metadata": {},
   "source": [
    "### Hadamard product\n",
    "If two tensors have the same size, operations are often by default applied element-wise. This is **not matrix multiplication**, which we'll cover later, but is rather called the <font color=red>**Hadamard product**</font> or simply the <font color=red>**element-wise product**. </font>\n",
    "\n",
    "The mathematical notation is $A \\odot X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "464349e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0ce8487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  4],\n",
       "       [ 7, 28],\n",
       "       [ 5,  9]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X+2\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12d3f9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[675,   8],\n",
       "       [ 35, 728],\n",
       "       [ 15,  63]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6eea8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_pt = X_pt + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ac59413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[675,   8],\n",
       "        [ 35, 728],\n",
       "        [ 15,  63]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pt * X_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa2811",
   "metadata": {},
   "source": [
    "### Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ee47f",
   "metadata": {},
   "source": [
    "Calculating the sum across all elements of a tensor is a common operation. For example: \n",
    "\n",
    "* For vector ***x*** of length *n*, we calculate $\\sum_{i=1}^{n} x_i$\n",
    "* For matrix ***X*** with *m* by *n* dimensions, we calculate $\\sum_{i=1}^{m} \\sum_{j=1}^{n} X_{i,j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a54c18b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  2],\n",
       "       [ 5, 26],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4e356c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c9b40baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(68)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f066229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 35])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also be done along one specific axis alone, e.g.:\n",
    "X.sum(axis=0) # summing over all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "424d4afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 31, 10])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(axis=1) # summing over all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "329b84a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([33, 35])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X_pt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "972beb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27, 31, 10])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(X_pt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439bfcd7",
   "metadata": {},
   "source": [
    "Many other operations can be applied with reduction along all or a selection of axes, e.g.:\n",
    "\n",
    "* maximum\n",
    "* minimum\n",
    "* mean\n",
    "* product\n",
    "\n",
    "They're fairly straightforward and used less often than summation, so you're welcome to look them up in library docs if you ever need them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac3927",
   "metadata": {},
   "source": [
    "### The Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792ba3f",
   "metadata": {},
   "source": [
    "For two vectors with the same length *n* $x, y \\in \\mathbb{R}^n$\n",
    "* $x \\cdot y$\n",
    "* $x^Ty$\n",
    "* $\\langle x,y \\rangle$\n",
    "\n",
    "Regardless which notation you use (I prefer the first), the calculation is the same; we calculate products in an element-wise fashion and then sum reductively across the products to a scalar value.\n",
    "\n",
    "$x \\cdot y = x^T y \\in \\mathbb{R} = \\begin{bmatrix} x_1 & x_2 & \\cdots & x_n \\end{bmatrix} \\begin{bmatrix} y_1 \\\\[0.3em] y_2 \\\\[0.3em] \\vdots \\\\[0.3em] y_n \\end{bmatrix} = \\sum_{i=1}^{n}{x_i y_i}$\n",
    "\n",
    "The inner products are a special case of matrix multiplication.\n",
    "\n",
    "It is always the case that $x^T y = y^T x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11e997c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 13, 42])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd45da54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0, 1, 2])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9bdf1aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*0 + 13*1 + 42*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "041e6769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8361028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 13, 42])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a791b029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pt = torch.tensor([0, 1, 2])\n",
    "y_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "94eb7872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x_pt, y_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f2c1185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(97.)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(torch.tensor([7, 13, 42.]), torch.tensor([0, 1, 2.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d9a8f",
   "metadata": {},
   "source": [
    "## Segment 3: Matrix Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b608f49",
   "metadata": {},
   "source": [
    "### Frobenius Norm\n",
    "\n",
    "* Discribed by: <font color=red>$||X||_{F}=\\sqrt{\\sum_{i, j} X_{i, j}^2}$</font>\n",
    "* Analogous to $L^2$ norm of vector\n",
    "* Measures the size of matrix in ters of Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47149b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f36134a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1**2 + 2**2 + 3**2 + 4**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b13d9a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X) # same function as for vector L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8784bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pt = torch.tensor([[1, 2], [3, 4.]]) # torch.norm() supports floats only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc162709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4772)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(X_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd233b8b",
   "metadata": {},
   "source": [
    "### Matrix Multiplication (with a Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff4be31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [5, 6],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[3, 4], [5, 6], [7, 8]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5362fcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([1, 2])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "48badc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 17, 23])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, b) # even though technically dot products are between vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "17a58950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pt = torch.tensor([[3, 4], [5, 6], [7, 8]])\n",
    "A_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f82b135f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_pt = torch.tensor([1, 2])\n",
    "b_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5340ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 17, 23])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A_pt, b_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5fb136",
   "metadata": {},
   "source": [
    "### Matrix Multiplication (with Two Matrices)\n",
    "The result of the multiplication of two matrixes $A \\in \\mathbb{R}^{m \\times n}$ and $B \\in \\mathbb{R}^{n \\times p}$ is the matrix:\n",
    "\n",
    "$C = AB \\in \\mathbb{R}^{m \\times n}$\n",
    "\n",
    "That is, we are multiplying the columns of $A$ with the rows of $B$:\n",
    "\n",
    "$C_{ij}=\\sum_{k=1}^n{A_{ij}B_{kj}}$\n",
    "\n",
    "The number of columns in $A$ must be equal to the number of rows in $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4534e78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [5, 6],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "14a0f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 9],\n",
       "       [2, 0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[1, 9], [2, 0]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "255a1d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 27],\n",
       "       [17, 45],\n",
       "       [23, 63]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4f069",
   "metadata": {},
   "source": [
    "Note that matrix multiplication is not \"commutative\" (i.e., $AB \\neq BA$) so uncommenting the following line will throw a size mismatch error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b12e3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.dot(B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d9e5ede9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 9],\n",
       "        [2, 0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_pt = torch.from_numpy(B)\n",
    "B_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cd5d1fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 9],\n",
       "        [2, 0]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another neat way to create the same tensor with transposition: \n",
    "B_pt = torch.tensor([[1, 2], [9, 0]]).T\n",
    "B_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b84b13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11, 27],\n",
       "        [17, 45],\n",
       "        [23, 63]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A_pt, B_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545b53b",
   "metadata": {},
   "source": [
    "## Special Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915e94d",
   "metadata": {},
   "source": [
    "### Symmetric Matrices\n",
    "\n",
    "* Square\n",
    "* $X^T = X$\n",
    "\n",
    "\\begin{pmatrix}\n",
    "0 & 1 & 2\\\\\n",
    "1 & 7 & 8\\\\\n",
    "2 & 8 & 9\n",
    "\\end{pmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01abd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sym = np.array([[0, 1, 2], [1, 7, 8], [2, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d125cbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sym.T == X_sym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe3a676",
   "metadata": {},
   "source": [
    "### Identity Matrices\n",
    "\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "0 & 1 & 0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ba00bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2203851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  2,  5])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt = torch.tensor([25, 2, 5])\n",
    "x_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f89d5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  2,  5])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(I, x_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf31dd8",
   "metadata": {},
   "source": [
    "### Hilbert matrix\n",
    "In linear algebra, a Hilbert matrix, introduced by Hilbert (1894), is a ***square matrix*** with entries being the unit fractions:\n",
    "\n",
    "$$ H_{i,j} = \\frac{1}{i + j - 1}$$\n",
    "\n",
    "\\begin{pmatrix}\n",
    "1 & 1/2 & 1/3\\\\\n",
    "1/2 & 1/3 & 1/4\\\\\n",
    "1/3 & 1/4 & 1/5\n",
    "\\end{pmatrix}\n",
    "\n",
    "The Hilbert matrix can be regarded as derived from the integral\n",
    "\n",
    "$$H_{i,j} = \\int_{0}^1 x^{i+j-2}dx$$\n",
    "\n",
    "Hilbert matrices are examples of \"ill-conditioned\" matrices that are difficult to use in numerical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0171aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a9b68ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.5       , 0.33333333],\n",
       "       [0.5       , 0.33333333, 0.25      ],\n",
       "       [0.33333333, 0.25      , 0.2       ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hilbert(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05bbd6",
   "metadata": {},
   "source": [
    "### Hermitian matrix\n",
    "In mathematics, a **Hermitian matrix** (or **self-adjoint matrix**) is a **complex square matrix** that is equal to its own **conjugate transpose**—that is, the element in the i-th row and j-th column is equal to the complex conjugate of the element in the j-th row and i-th column\n",
    "for all indices i and j:\n",
    "\n",
    "$$ A Hermitian \\leftrightarrow a_{ij} = \\overline{a_{ij}} $$\n",
    "\n",
    "\\begin{pmatrix}\n",
    "3 & 3 + i\\\\\n",
    "3 - i & 2\n",
    "\\end{pmatrix}\n",
    "\n",
    "complex conjugates:\n",
    "\n",
    "\\begin{pmatrix}\n",
    "3 & 3 - i\\\\\n",
    "3 + i & 2\n",
    "\\end{pmatrix}\n",
    "\n",
    "Transpose:\n",
    "\n",
    "\\begin{pmatrix}\n",
    "3 & 3 + i\\\\\n",
    "3 - i & 2\n",
    "\\end{pmatrix}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58d0c7",
   "metadata": {},
   "source": [
    "### Jacobian matrix\n",
    "\n",
    "$$ J_{i, j} = \\displaystyle \\frac{\\partial f_i}{\\partial x_{j}} $$\n",
    "\n",
    "\\begin{equation}\n",
    "J_{f}=\\begin{bmatrix}\\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_{2}} & \\cdots & \\frac{\\partial f_1}{\\partial x_{n}}\\\\\n",
    "\\frac{\\partial f_2}{\\partial x_{1}} & \\frac{\\partial f_2}{\\partial x_{2}} & \\cdots & \\frac{\\partial f_2}{\\partial x_{n}}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial f_m}{\\partial x_{1}} & \\frac{\\partial f_m}{\\partial x_{2}} & \\cdots & \\frac{\\partial f_m}{\\partial x_{n}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f383f2f",
   "metadata": {},
   "source": [
    "### Hessian matrix\n",
    "\n",
    "\\begin{equation}\n",
    "H_{f}=\\begin{bmatrix}\\frac{\\partial^{2}f}{\\partial x_{1}^{2}} & \\frac{\\partial^{2}f}{\\partial x_{1}\\partial x_{2}} & \\cdots & \\frac{\\partial^{2}f}{\\partial x_{1}\\partial x_{n}}\\\\\n",
    "\\frac{\\partial^{2}f}{\\partial x_{2}\\partial x_{1}} & \\frac{\\partial^{2}f}{\\partial x_{2}^{2}} & \\cdots & \\frac{\\partial^{2}f}{\\partial x_{2}\\partial x_{n}}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\partial^{2}f}{\\partial x_{n}\\partial x_{1}} & \\frac{\\partial^{2}f}{\\partial x_{n}\\partial x_{2}} & \\cdots & \\frac{\\partial^{2}f}{\\partial x_{n}^{2}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "That is, the entry of the i-th row and the j-th column is:\n",
    "\n",
    "$$ (H_f)_{i,j} = \\displaystyle \\frac{\\partial^{2}f}{\\partial x_{i}\\partial x_{j}} $$\n",
    "\n",
    "The Hessian matrix of a function $f$ is the ***Jacobian matrix*** of the gradient of the function $f$; that is:\n",
    "\n",
    "$$ H(f(x)) = J(\\nabla f(x))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df71d5c",
   "metadata": {},
   "source": [
    "## Matrix Inversion\n",
    "\n",
    "$X^{-1}X = I_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d287073d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  2],\n",
       "       [-5, -3]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[4, 2], [-5, -3]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "09ed5c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5,  1. ],\n",
       "       [-2.5, -2. ]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xinv = np.linalg.inv(X)\n",
    "Xinv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57394abf",
   "metadata": {},
   "source": [
    "### Matrix Inversion Where No Solution\n",
    "Can only be calculated if:\n",
    "* Matrix isn't \"singular\"\n",
    "   * that is, all columns of matrix must be linearly independent\n",
    "   * Matrix is square $n_{row} = n_{col}$ (i.e. \"vector span\" = \"matrix range\"\n",
    "      * avoids \"Overdetermination\" $n_{row} > n_{col}$ (i.e. $n_{equations} > n_{dimensions}$)\n",
    "      * avoids \"Underdetermination\" $n_{row} < n_{col}$ (i.e. $n_{equations} < n_{dimensions}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d528a",
   "metadata": {},
   "source": [
    "Note that solving equation may still be possible by other means if matrix can't be inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d2cac676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4,  1],\n",
       "       [-8,  2]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[-4, 1], [-8, 2]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncommenting the following line results in a \"singular matrix\" error\n",
    "# Xinv = np.linalg.inv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a700ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
